# -*- coding: utf-8 -*-
"""MODELING .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WJNbvt8qL7ThiZTtzIR1-KCOKEnx64fl
"""

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from google.colab import drive
drive.mount('/content/drive')
data = pd.read_csv("/content/drive/MyDrive/winequality.csv")

# dividing the dataset into dependent and independent variables

x = data.iloc[:,:11]
y = data.iloc[:,11]

# determining the shape of x and y.
print(x.shape)
print(y.shape)

# dividing the dataset in training and testing set

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 44)

# determining the shapes of training and testing sets
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

# standard scaling
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

"""MODELING

LOGISTIC REGRESSION
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

from sklearn.model_selection import GridSearchCV, cross_val_score



# creating the model
model = LogisticRegression()

# feeding the training set into the model
model.fit(x_train, y_train)

# predicting the results for the test set
y_pred = model.predict(x_test)

# calculating the training and testing accuracies
print("Training accuracy :", model.score(x_train, y_train))
print("Testing accuracy :", model.score(x_test, y_test))

# classification report
print(classification_report(y_test, y_pred))

# confusion matrix
print(confusion_matrix(y_test, y_pred))

from sklearn.linear_model import SGDClassifier

# creating the model
model = SGDClassifier(penalty=None)

# feeding the training model into the model
model.fit(x_train, y_train)

# predicting the values for the test set
y_pred = model.predict(x_test)

# classification report
print(classification_report(y_test, y_pred))

"""SUPPORT VECTOR MATCHINE"""

from sklearn.svm import SVC

# creating the model
model = SVC()

# feeding the training set into the model
model.fit(x_train, y_train)

# predicting the results for the test set
y_pred = model.predict(x_test)

# calculating the training and testing accuracies
print("Training accuracy :", model.score(x_train, y_train))
print("Testing accuracy :", model.score(x_test, y_test))

param = {
    'C': [0.8,0.9,1,1.1,1.2,1.3,1.4],
    'kernel':['linear', 'rbf'],
    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]
}
grid_svc = GridSearchCV(model, param_grid = param, scoring = 'accuracy', cv = 10)

from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

# Load your dataset
data = pd.read_csv("/content/drive/MyDrive/winequality.csv")

# creating the model
model = SVC()

# finding the best parameters for the SVC model

param = {
    'C': [0.8,0.9,1,1.1,1.2,1.3,1.4],
    'kernel':['linear', 'rbf'],
    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]
}
grid_svc = GridSearchCV(model, param_grid = param, scoring = 'accuracy', cv = 10)

# dividing the dataset into dependent and independent variables
x = data.iloc[:,:11]
y = data.iloc[:,11]

# dividing the dataset in training and testing set
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 44)

grid_svc.fit(x_train, y_train)

# classification report
print(classification_report(y_test, y_pred))

# confusion matrix
print(confusion_matrix(y_test, y_pred))

"""DECISION FOREST

"""

from sklearn.ensemble import RandomForestClassifier

# creating the model
model = RandomForestClassifier(n_estimators = 200)

# feeding the training set into the model
model.fit(x_train, y_train)

# predicting the results for the test set
y_pred = model.predict(x_test)

# calculating the training and testing accuracies
print("Training accuracy :", model.score(x_train, y_train))
print("Testing accuracy :", model.score(x_test, y_test))

#Now lets try to do some evaluation for decision tree model using cross validation.

model_eval = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 10)
model_eval.mean()

"""RANDOM FOREST"""

from sklearn.ensemble import RandomForestClassifier

# creating the model
model = RandomForestClassifier(n_estimators = 200)

# feeding the training set into the model
model.fit(x_train, y_train)

# predicting the results for the test set
y_pred = model.predict(x_test)

# calculating the training and testing accuracies
print("Training accuracy :", model.score(x_train, y_train))
print("Testing accuracy :", model.score(x_test, y_test))

# classification report
print(classification_report(y_test, y_pred))

# confusion matrix
print(confusion_matrix(y_test, y_pred))

#Now lets try to do some evaluation for random forest model using cross validation.

model_eval = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 10)
model_eval.mean()

"""Multi Layer Perceptron"""

from sklearn.neural_network import MLPClassifier

# creating the model
model = MLPClassifier(hidden_layer_sizes = (100, 100), max_iter = 150)

# feeding the training data to the model
model.fit(x_train, y_train)

# calculating the accuracies
print("training accuracy :", model.score(x_train, y_train))
print("testing accuracy :", model.score(x_test, y_test))

"""Artificial Neural Networks"""

import keras
from keras.models import Sequential
from keras.layers import Dense

from keras.utils import to_categorical

# Determine the number of classes (unique wine quality ratings)
num_classes = len(y.unique())

# One-hot encode the target variables
y_train_encoded = to_categorical(y_train - y_train.min(), num_classes=num_classes) # Adjust for 0-based indexing
y_test_encoded = to_categorical(y_test - y_test.min(), num_classes=num_classes)

print(f"Original y_train shape: {y_train.shape}")
print(f"Encoded y_train shape: {y_train_encoded.shape}")
print(f"First 5 original y_train values:\n{y_train.head()}")
print(f"First 5 encoded y_train values:\n{y_train_encoded[:5]}")

from keras.models import Sequential
from keras.layers import Dense

# creating the model
model = Sequential()

# first hidden layer
model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))

# second hidden layer
model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))

# output layer: units changed to num_classes and activation to 'softmax'
model.add(Dense(units=num_classes, kernel_initializer = 'uniform', activation = 'softmax'))

# Compiling the NN: loss function changed to 'categorical_crossentropy'
model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

# Fitting the model with one-hot encoded y_train
model.fit(x_train, y_train_encoded, batch_size = 10, epochs = 100)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(x_test, y_test_encoded)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

import joblib
joblib.dump(model, "wine_quality_model.pkl")

import joblib

joblib.dump(model, "wine_quality_model.pkl")
joblib.dump(sc, "wine_scaler.pkl")

print("Model saved successfully!")

import joblib
import numpy as np

# Load model and scaler
model = joblib.load("wine_quality_model.pkl")
scaler = joblib.load("wine_scaler.pkl")

# SAMPLE INPUT (you can change anytime)
sample_input = np.array([[
    7.4,    # fixed acidity
    0.70,   # volatile acidity
    0.00,   # citric acid
    1.9,    # residual sugar
    0.076,  # chlorides
    11,     # free sulfur dioxide
    34,     # total sulfur dioxide
    0.9978, # density
    3.51,   # pH
    0.56,   # sulphates
    9.4     # alcohol
]])

# Scale input
scaled_input = scaler.transform(sample_input)

# Predict quality probabilities
quality_probabilities = model.predict(scaled_input)[0]

# Get the predicted class index (0-indexed) and convert to actual quality score
# Assuming y.min() was 3 based on previous steps where y_train_encoded was y_train - y_train.min()
predicted_class_index = np.argmax(quality_probabilities)
quality = predicted_class_index + 3 # Add the minimum original quality score

# GOOD/BAD logic
if quality <= 4:
    label = "BAD wine"
elif quality == 5:
    label = "AVERAGE wine"
else:
    label = "GOOD wine"

print("Predicted Quality:", quality)
print("This is a", label)

import gradio as gr
import joblib
import numpy as np

# Load model and scaler
model = joblib.load("wine_quality_model.pkl")
scaler = joblib.load("wine_scaler.pkl")

def predict_quality(fixed_acidity, volatile_acidity, citric_acid, residual_sugar,
                    chlorides, free_sulfur_dioxide, total_sulfur_dioxide,
                    density, pH, sulphates, alcohol):

    sample = np.array([[fixed_acidity, volatile_acidity, citric_acid, residual_sugar,
                        chlorides, free_sulfur_dioxide, total_sulfur_dioxide,
                        density, pH, sulphates, alcohol]])

    scaled = scaler.transform(sample)
    pred = model.predict(scaled)[0]

    return "GOOD ðŸ·" if pred == 1 else "BAD âŒ"

inputs = [
    gr.Number(label="Fixed Acidity"),
    gr.Number(label="Volatile Acidity"),
    gr.Number(label="Citric Acid"),
    gr.Number(label="Residual Sugar"),
    gr.Number(label="Chlorides"),
    gr.Number(label="Free Sulfur Dioxide"),
    gr.Number(label="Total Sulfur Dioxide"),
    gr.Number(label="Density"),
    gr.Number(label="pH"),
    gr.Number(label="Sulphates"),
    gr.Number(label="Alcohol"),
]

output = gr.Textbox(label="Prediction")

app = gr.Interface(
    fn=predict_quality,
    inputs=inputs,
    outputs=output,
    title="Wine Quality Prediction App",
    description="Enter wine chemistry values to predict if wine is GOOD or BAD"
)

app.launch()